---
comments: true
title:  "SpeechBot - le commencement"
date:   2025-03-18
tags:
    - D√©veloppement
    - Agent
    - LLM
    - Parole
    - Apprentissage automatique
    - Python
hide:
    - navigation
excerpt: Comment cr√©er rapidement un agent de parole √† parole efficace.
---

Ce post est le point de d√©part de ma nouvelle s√©rie de tutoriels sur la cr√©ation d'un agent de parole √† parole efficient.
Nous examinerons les choix faits et le type d'architecture choisi.
Dans ce post, nous nous concentrerons sur la version initiale disponnible sur [GitHub](https://github.com/vroger11/SpeechBot).
L'objectif est d'avoir une solution performante qui peut fonctionner sur une configuration de bureau moyenne (j'ai utilis√© un AMD Ryzen 7 5700X, 32 Go de RAM et une NVIDIA RTX 4060).
Vous pouvez voir l'application en action sur [YouTube](https://youtu.be/5Cik2asxGfM) ou vous pouvez l'essayer sur votre machine.
Tous les mod√®les utilis√©s sont rassembl√©s sur Hugging Face Hub, et la solution est construite en utilisant plusieurs mod√®les au lieu d'un seul.

## **Architecture de SpeechBot**

SpeechBot est con√ßu comme un syst√®me modulaire o√π chaque composant g√®re une fonction sp√©cifique dans le pipeline d'interaction vocale. Au lieu d'utiliser un mod√®le de parole √† parole (o√π les mod√®les SOTA utilisent des milliards de param√®tres et sont difficiles √† am√©liorer), j'ai pr√©f√©r√© utiliser cette solution car elle est simple √† mettre en ≈ìuvre et simple √† mettre √† niveau.

De plus, cr√©er un programme unique qui utilise et importe tous les mod√®les est difficile et peut √™tre impossible car chaque mod√®le a ses exigences de d√©pendance qui peuvent √™tre incompatibles.
Ainsi, j'ai opt√© pour cr√©er un service par mod√®le, et un dernier pour le frontend, en utilisant FastAPI pour chaque service utilisant un mod√®le (STT, LLM, TTS).

Ainsi, l'architecture globale contient les composants suivants :

```mermaid
graph TD
   User["üéô Utilisateur"] -->|Parle| Frontend;
   Frontend["üñ• Frontend (Streamlit)"] -->|Envoie l'audio| STT["üó£ Speech-to-Text (STT)"];
   STT -->|Texte transcrit| Frontend;
   Frontend -->|Texte transcrit| LLM["üß† Large Language Model (LLM)"];
   LLM -->|R√©ponse textuelle g√©n√©r√©e| Frontend;
   Frontend -->|R√©ponse textuelle g√©n√©r√©e| TTS["üîä Text-to-Speech (TTS)"];
   TTS -->|Audio g√©n√©r√©| Frontend;
   Frontend -->|Montre les r√©sultats interm√©diaires| User;
   Frontend -->|Joue la r√©ponse| User;

   subgraph Services
      STT
      LLM
      TTS
   end

   subgraph System
      Frontend
      Services
   end
```

Les d√©tails de chaque composant sont les suivants :

1. **Frontend (utilisant Streamlit)**
    - Capture la parole de l'utilisateur via un microphone.
    - Assure la communication entre les services.
        - Envoie l'audio enregistr√© au service Speech-to-Text (STT) pour obtenir la transcription.
        - Re√ßoit des r√©ponses textuelles du service Large Language Model (LLM) √©tant donn√© la transcription.
        - Obtient la parole du service Text-to-Speech (TTS).
    - Joue la parole g√©n√©r√©e.
    - Montre √† l'utilisateur le r√©sultat de chaque √©tape.

2. **Service Speech-to-Text (STT)**
    - Convertit l'entr√©e parl√©e en texte.
    - Utilise un mod√®le (Whisper tiny) pour effectuer la transcription.

3. **Service Large Language Model (LLM)**
    - Traite le texte transcrit et g√©n√®re une r√©ponse.
    - Utilise un mod√®le pour comprendre le contexte (version distill√©e de Qwen 2.5) et g√©n√©rer des r√©ponses ayant du sens.

4. **Service Text-to-Speech (TTS)**
    - Convertit le texte g√©n√©r√© en parole.
    - Utilise un mod√®le pour synth√©tiser la voix de l'agent (tiny TTS-parler).

## Biblioth√®ques utilis√©es

Chaque service et le frontend sont dockeris√©s et peuvent √™tre lanc√©s en utilisant Docker Compose.
Alors que le frontend est √©crit en utilisant Streamlit, chaque service est √©crit comme une API REST (en utilisant FastAPI) avec des biblioth√®ques associ√©es aux mod√®les sous le capot (llama-cpp ou transformers).
Voici les d√©tails de pourquoi j'ai s√©lectionn√© ces biblioth√®ques :

### Streamlit

Streamlit est une libraire open-source qui vous permet de cr√©er de belles applications web pour les projets de machine learning et de science des donn√©es avec un minimum d'effort. Il est utilis√© pour le frontend pour capturer la parole de l'utilisateur, afficher les √©tapes interm√©diaires et jouer la parole g√©n√©r√©e.

### FastAPI

FastAPI est une librarie web moderne, rapide (haute performance) pour la cr√©ation d'API avec Python bas√© sur les annotations de type standard de Python. Il est utilis√© pour cr√©er des API REST pour chaque service (STT, LLM, TTS) en raison de sa rapidit√© et de sa facilit√© d'utilisation. De plus, la g√©n√©ration automatique de documentation Swagger et ReDoc (j'utilise Swagger pour tester mes services ind√©pendamment) le rend adapt√© au d√©veloppement rapide.

!!! warning "Avertissement"
    Cette application dans sa premi√®re version est con√ßue pour un seul utilisateur. La mise en ≈ìuvre des services FastAPI n'est pas √©crite pour des utilisateurs concurrents.

### Docker Compose

Docker Compose est un outil pour d√©finir et ex√©cuter des applications multi-conteneurs Docker. Il est utilis√© pour g√©rer les services et leurs d√©pendances, assurant une communication transparente entre tous les composants. En utilisant son sous-r√©seau, je peux facilement acc√©der aux services depuis le frontend (en utilisant des adresses comme `http://llm_service:8000`). Il simplifie √©galement le d√©ploiement et la gestion de tous les services.

!!! note "Note"
    Sur les serveurs cloud avec plusieurs clients, vous pr√©f√©rerez Terraform associ√© √† Kubernetes au lieu de Docker Compose.

### Hugging Face Transformers

Hugging Face Transformers est une biblioth√®que qui fournit des architectures √† usage g√©n√©ral pour la compr√©hension et la g√©n√©ration de langage naturel avec des mod√®les pr√©-entra√Æn√©s. Elle est utilis√©e pour les services STT et TTS pour traiter le texte transcrit et g√©n√©rer des r√©ponses.

### LlamaCpp

LlamaCpp est une biblioth√®que qui fournit des impl√©mentations efficaces de divers mod√®les LLM. Je la pr√©f√®re √† la biblioth√®que transformers car elle offre de meilleures performances brutes.

## Mod√®les utilis√©s

Tous les mod√®les sont disponibles sur le [Hugging Face Hub](https://huggingface.co/), une ressource inestimable pour acc√©der √† une large gamme de mod√®les et de jeux de donn√©es.

Pour le mod√®le STT, [Whisper tiny](https://huggingface.co/openai/whisper-tiny) a √©t√© s√©lectionn√© pour accomplir cette t√¢che car il obtient de bons r√©sultats sur GPU et n'est pas gourmand en VRAM.

Pour le LLM, j'ai utilis√© une [version distill√©e de Qwen 2.5](https://huggingface.co/bartowski/Qwen2.5.1-Coder-7B-Instruct-GGUF) pour √™tre efficace sur CPU (car les mod√®les STT et TTS ne laissent pas assez de m√©moire VRAM), car la performance √©tait suffisante pour cette premi√®re version. Pour les futures versions, j'explorerai plus de mod√®les comme GEMINI de Google.

Pour le mod√®le TTS, j'ai s√©lectionn√© une version tiny de [tiny TTS-parler](https://huggingface.co/parler-tts/parler-tts-tiny-v1) pour s'assurer qu'il fonctionne efficacement sur les ressources disponibles.

!!! info "Besoin de vos retours"
    Si vous connaissez de meilleurs mod√®les que je pourrais utiliser, n'h√©sitez pas √† me contacter pour que nous puissions en discuter. J'ai vu par la suite l'approche [speech-to-speech](https://github.com/huggingface/speech-to-speech) de Hugging Face qui a fait des choix similaires. Je prendrai leur approche en compte dans les futurs posts.

## Ce qui vient ensuite

Le prochain post de cette s√©rie portera sur la fa√ßon d'am√©liorer les performances, alors restez √† l'√©coute (vous pouvez suivre mon flux RSS ou me suivre sur [LinkedIn](https://www.linkedin.com/in/vroger11/)).
J'esp√®re que vous avez appr√©ci√©, tout retour est le bienvenu.

√Ä bient√¥t,

Vincent
